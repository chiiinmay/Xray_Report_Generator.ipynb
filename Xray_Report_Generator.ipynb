{"nbformat": 4, "nbformat_minor": 5, "metadata": {"language_info": {"name": "python"}}, "cells": [{"id": "071706a5", "cell_type": "markdown", "source": "# X-Ray Report Generator with Vision-Language Model in Colab (Enhanced)", "metadata": {}}, {"id": "ea7e491d", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "!pip install transformers datasets torchvision evaluate -q", "outputs": []}, {"id": "2e212d2d", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import torch\nfrom transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nimport os", "outputs": []}, {"id": "f0d7cd6a", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\nfeature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\ntokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()", "outputs": []}, {"id": "b841f51b", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "def preprocess_image(image_path, to_grayscale=False, resize=(224, 224)):\n    image = Image.open(image_path).convert(\"RGB\")\n    if to_grayscale:\n        image = ImageOps.grayscale(image).convert(\"RGB\")\n    if resize:\n        image = image.resize(resize)\n    return image", "outputs": []}, {"id": "fa63e818", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "def generate_report(image):\n    pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n    output_ids = model.generate(pixel_values, max_length=64, num_beams=4)\n    text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n    report = f\"\"\"\n    ===== RADIOLOGY REPORT =====\n    Findings:\n    {text}\n\n    Impression:\n    Based on visual features, automated findings suggest above observations.\n\n    Confidence: N/A (Not computed)\n    =============================\n    \"\"\"\n    return report.strip()", "outputs": []}, {"id": "cac7dd36", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "input_dir = \"/content/xray_samples\"  # Directory containing images\noutput_file = \"batch_generated_reports.txt\"\n\nos.makedirs(input_dir, exist_ok=True)\nimage_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n\nwith open(output_file, \"w\") as f:\n    for image_name in image_files:\n        image_path = os.path.join(input_dir, image_name)\n        image = preprocess_image(image_path, to_grayscale=True)\n\n        plt.imshow(image)\n        plt.title(image_name)\n        plt.axis('off')\n        plt.show()\n\n        report = generate_report(image)\n        print(\"\\n\\033[1mGenerated Report for:\\033[0m\", image_name)\n        print(report)\n\n        f.write(f\"Report for {image_name}:\\n{report}\\n\\n\")", "outputs": []}, {"id": "68dfa216", "cell_type": "markdown", "source": "## Project Attribution and License\n\nThis project uses the pretrained model `nlpconnect/vit-gpt2-image-captioning` from Hugging Face, licensed under the MIT License.\nNo real patient data is used in this example. The sample images and generated outputs are for educational and research purposes only.\nThis notebook is intended as a starting point for developing real-world AI applications in medical imaging, but is not validated for clinical use.\n\n**Author**: chiiinmay  \nParts of this project were assisted by OpenAI\u2019s ChatGPT to accelerate prototyping and documentation.\n\n---\n\n### Reuse & Attribution\nThis project is licensed under the MIT License. If you use this code or parts of it, please provide credit by linking to:  \n\ud83d\udc49 https://github.com/chiiinmay/xray-report-generator\n\n---\n\n### \ud83d\udcda Citation\nIf you use this project or build upon it, please cite it as:\n\n```\n@misc{chiiinmay_xrayreport_2025,\n  author       = {Chiiinmay},\n  title        = {X-Ray Report Generator using Vision-Language Models},\n  year         = {2025},\n  howpublished = {\\url{https://github.com/chiiinmay/xray-report-generator}},\n  note         = {Developed using Hugging Face Transformers and assisted by OpenAI's ChatGPT.}\n}\n```", "metadata": {}}]}